from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from paddleocr import PaddleOCR
from faster_whisper import WhisperModel
from PIL import Image
import numpy as np
import io
import cv2
import tempfile
import os

app = FastAPI()

# CORS æ”¯æ´ï¼ˆè®“ Streamlit å‰ç«¯å¯è·¨ç¶²åŸŸé€£ç·šï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ¨¡å‹
ocr_model = PaddleOCR(use_angle_cls=True, lang='ch')  # Mobile æ¨¡å‹å·²å…§å»º
whisper_model = WhisperModel("tiny", device="cpu", compute_type="int8")

# âœ… OCR APIï¼šåœ–ç‰‡è¾¨è­˜
@app.post("/ocr")
async def ocr_endpoint(file: UploadFile = File(...)):
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        print(f"ğŸ“¸ åœ–ç‰‡å¤§å°ï¼š{image.size}")  # âœ… Debugï¼šç¢ºèªæœ‰åœ–
        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        result = ocr_model.ocr(img, cls=True)
        text = "\n".join([line[1][0] for box in result for line in box])
        return {"text": text}
    except Exception as e:
        print("âŒ OCR éŒ¯èª¤ï¼š", e)  # âœ… é¡¯ç¤ºéŒ¯èª¤ç´°ç¯€
        return {"error": str(e)}

# âœ… Whisper APIï¼šèªéŸ³è¾¨è­˜
@app.post("/whisper")
async def whisper_endpoint(file: UploadFile = File(...)):
    try:
        contents = await file.read()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(contents)
            tmp_path = tmp.name

        segments, _ = whisper_model.transcribe(
            tmp_path, language="zh", beam_size=5, vad_filter=True
        )
        text = " ".join([seg.text.strip() for seg in segments])
        return {"text": text}
    except Exception as e:
        return {"error": str(e)}

# âœ… è®“ Render æ­£å¸¸ç¶å®š port
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("ocr_api:app", host="0.0.0.0", port=port)
